{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enjoy/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/enjoy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/enjoy/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/enjoy/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-86d695196f9e>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/enjoy/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/enjoy/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/enjoy/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/enjoy/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/enjoy/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#读入数据\n",
    "mnist = input_data.read_data_sets('./mnist', one_hot=True)#代码和数据集文件夹放在同一目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fcb6e9fac88>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fcb6e7702e8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fcb6e770278>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从正态分布输出随机值\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判别模型的输入和参数初始化\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([784, 128]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([128, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成模型的输入和参数初始化\n",
    "Z = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([100, 128]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([128, 784]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[784]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机噪声采样函数\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成模型\n",
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "\n",
    "    return G_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判别模型\n",
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画图函数\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#喂入数据\n",
    "G_sample = generator(Z)\n",
    "D_real, D_logit_real = discriminator(X)\n",
    "D_fake, D_logit_fake = discriminator(G_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算losses:\n",
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real))) \n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake))) \n",
    "D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 128\n",
    "Z_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 1.384\n",
      "G_loss: 1.901\n",
      "Iter: 1000\n",
      "D loss: 0.005322\n",
      "G_loss: 9.225\n",
      "Iter: 2000\n",
      "D loss: 0.05466\n",
      "G_loss: 6.155\n",
      "Iter: 3000\n",
      "D loss: 0.06856\n",
      "G_loss: 4.804\n",
      "Iter: 4000\n",
      "D loss: 0.09323\n",
      "G_loss: 5.595\n",
      "Iter: 5000\n",
      "D loss: 0.3351\n",
      "G_loss: 4.6\n",
      "Iter: 6000\n",
      "D loss: 0.2185\n",
      "G_loss: 4.969\n",
      "Iter: 7000\n",
      "D loss: 0.5018\n",
      "G_loss: 4.528\n",
      "Iter: 8000\n",
      "D loss: 0.2972\n",
      "G_loss: 4.154\n",
      "Iter: 9000\n",
      "D loss: 0.7718\n",
      "G_loss: 2.88\n",
      "Iter: 10000\n",
      "D loss: 0.7699\n",
      "G_loss: 2.787\n",
      "Iter: 11000\n",
      "D loss: 0.7579\n",
      "G_loss: 2.666\n",
      "Iter: 12000\n",
      "D loss: 0.6514\n",
      "G_loss: 3.369\n",
      "Iter: 13000\n",
      "D loss: 0.7493\n",
      "G_loss: 2.158\n",
      "Iter: 14000\n",
      "D loss: 0.76\n",
      "G_loss: 2.228\n",
      "Iter: 15000\n",
      "D loss: 0.8387\n",
      "G_loss: 2.174\n",
      "Iter: 16000\n",
      "D loss: 0.7019\n",
      "G_loss: 2.14\n",
      "Iter: 17000\n",
      "D loss: 0.654\n",
      "G_loss: 2.537\n",
      "Iter: 18000\n",
      "D loss: 0.5989\n",
      "G_loss: 2.686\n",
      "Iter: 19000\n",
      "D loss: 0.717\n",
      "G_loss: 2.353\n",
      "Iter: 20000\n",
      "D loss: 0.9036\n",
      "G_loss: 2.227\n",
      "Iter: 21000\n",
      "D loss: 0.7686\n",
      "G_loss: 2.0\n",
      "Iter: 22000\n",
      "D loss: 0.7219\n",
      "G_loss: 2.291\n",
      "Iter: 23000\n",
      "D loss: 0.5837\n",
      "G_loss: 2.013\n",
      "Iter: 24000\n",
      "D loss: 0.6134\n",
      "G_loss: 2.195\n",
      "Iter: 25000\n",
      "D loss: 0.6251\n",
      "G_loss: 2.525\n",
      "Iter: 26000\n",
      "D loss: 0.8006\n",
      "G_loss: 2.283\n",
      "Iter: 27000\n",
      "D loss: 0.6222\n",
      "G_loss: 2.229\n",
      "Iter: 28000\n",
      "D loss: 0.5911\n",
      "G_loss: 2.195\n",
      "Iter: 29000\n",
      "D loss: 0.7242\n",
      "G_loss: 2.267\n",
      "Iter: 30000\n",
      "D loss: 0.66\n",
      "G_loss: 2.287\n",
      "Iter: 31000\n",
      "D loss: 0.5233\n",
      "G_loss: 3.018\n",
      "Iter: 32000\n",
      "D loss: 0.7382\n",
      "G_loss: 2.578\n",
      "Iter: 33000\n",
      "D loss: 0.6852\n",
      "G_loss: 2.356\n",
      "Iter: 34000\n",
      "D loss: 0.8081\n",
      "G_loss: 2.338\n",
      "Iter: 35000\n",
      "D loss: 0.6899\n",
      "G_loss: 2.616\n",
      "Iter: 36000\n",
      "D loss: 0.6225\n",
      "G_loss: 2.432\n",
      "Iter: 37000\n",
      "D loss: 0.6257\n",
      "G_loss: 2.403\n",
      "Iter: 38000\n",
      "D loss: 0.7604\n",
      "G_loss: 2.588\n",
      "Iter: 39000\n",
      "D loss: 0.6778\n",
      "G_loss: 3.055\n",
      "Iter: 40000\n",
      "D loss: 0.5913\n",
      "G_loss: 2.528\n",
      "Iter: 41000\n",
      "D loss: 0.5818\n",
      "G_loss: 2.529\n",
      "Iter: 42000\n",
      "D loss: 0.4899\n",
      "G_loss: 2.653\n",
      "Iter: 43000\n",
      "D loss: 0.6463\n",
      "G_loss: 2.707\n",
      "Iter: 44000\n",
      "D loss: 0.5669\n",
      "G_loss: 2.897\n",
      "Iter: 45000\n",
      "D loss: 0.7312\n",
      "G_loss: 2.778\n",
      "Iter: 46000\n",
      "D loss: 0.5218\n",
      "G_loss: 2.634\n",
      "Iter: 47000\n",
      "D loss: 0.566\n",
      "G_loss: 2.615\n",
      "Iter: 48000\n",
      "D loss: 0.6109\n",
      "G_loss: 2.603\n",
      "Iter: 49000\n",
      "D loss: 0.5717\n",
      "G_loss: 2.516\n",
      "Iter: 50000\n",
      "D loss: 0.6331\n",
      "G_loss: 2.72\n",
      "Iter: 51000\n",
      "D loss: 0.5594\n",
      "G_loss: 2.257\n",
      "Iter: 52000\n",
      "D loss: 0.5712\n",
      "G_loss: 2.729\n",
      "Iter: 53000\n",
      "D loss: 0.5022\n",
      "G_loss: 2.395\n",
      "Iter: 54000\n",
      "D loss: 0.5569\n",
      "G_loss: 2.287\n",
      "Iter: 55000\n",
      "D loss: 0.4928\n",
      "G_loss: 2.505\n",
      "Iter: 56000\n",
      "D loss: 0.6125\n",
      "G_loss: 2.695\n",
      "Iter: 57000\n",
      "D loss: 0.5535\n",
      "G_loss: 2.306\n",
      "Iter: 58000\n",
      "D loss: 0.6563\n",
      "G_loss: 2.561\n",
      "Iter: 59000\n",
      "D loss: 0.4605\n",
      "G_loss: 2.613\n",
      "Iter: 60000\n",
      "D loss: 0.5696\n",
      "G_loss: 2.917\n",
      "Iter: 61000\n",
      "D loss: 0.6018\n",
      "G_loss: 2.098\n",
      "Iter: 62000\n",
      "D loss: 0.6911\n",
      "G_loss: 2.764\n",
      "Iter: 63000\n",
      "D loss: 0.5117\n",
      "G_loss: 2.158\n",
      "Iter: 64000\n",
      "D loss: 0.5076\n",
      "G_loss: 2.879\n",
      "Iter: 65000\n",
      "D loss: 0.5787\n",
      "G_loss: 2.232\n",
      "Iter: 66000\n",
      "D loss: 0.6082\n",
      "G_loss: 2.341\n",
      "Iter: 67000\n",
      "D loss: 0.7116\n",
      "G_loss: 2.411\n",
      "Iter: 68000\n",
      "D loss: 0.5461\n",
      "G_loss: 2.482\n",
      "Iter: 69000\n",
      "D loss: 0.5502\n",
      "G_loss: 2.724\n",
      "Iter: 70000\n",
      "D loss: 0.6097\n",
      "G_loss: 2.708\n",
      "Iter: 71000\n",
      "D loss: 0.5631\n",
      "G_loss: 2.514\n",
      "Iter: 72000\n",
      "D loss: 0.626\n",
      "G_loss: 2.337\n",
      "Iter: 73000\n",
      "D loss: 0.6618\n",
      "G_loss: 2.536\n",
      "Iter: 74000\n",
      "D loss: 0.5742\n",
      "G_loss: 2.647\n",
      "Iter: 75000\n",
      "D loss: 0.4697\n",
      "G_loss: 3.018\n",
      "Iter: 76000\n",
      "D loss: 0.6159\n",
      "G_loss: 2.428\n",
      "Iter: 77000\n",
      "D loss: 0.4314\n",
      "G_loss: 2.742\n",
      "Iter: 78000\n",
      "D loss: 0.5419\n",
      "G_loss: 2.461\n",
      "Iter: 79000\n",
      "D loss: 0.5263\n",
      "G_loss: 2.489\n",
      "Iter: 80000\n",
      "D loss: 0.6383\n",
      "G_loss: 2.569\n",
      "Iter: 81000\n",
      "D loss: 0.5245\n",
      "G_loss: 2.442\n",
      "Iter: 82000\n",
      "D loss: 0.5742\n",
      "G_loss: 2.515\n",
      "Iter: 83000\n",
      "D loss: 0.557\n",
      "G_loss: 2.831\n",
      "Iter: 84000\n",
      "D loss: 0.4855\n",
      "G_loss: 2.706\n",
      "Iter: 85000\n",
      "D loss: 0.6236\n",
      "G_loss: 2.52\n",
      "Iter: 86000\n",
      "D loss: 0.6263\n",
      "G_loss: 2.634\n",
      "Iter: 87000\n",
      "D loss: 0.6032\n",
      "G_loss: 2.653\n",
      "Iter: 88000\n",
      "D loss: 0.5494\n",
      "G_loss: 2.496\n",
      "Iter: 89000\n",
      "D loss: 0.5625\n",
      "G_loss: 2.691\n",
      "Iter: 90000\n",
      "D loss: 0.5595\n",
      "G_loss: 2.409\n",
      "Iter: 91000\n",
      "D loss: 0.6029\n",
      "G_loss: 2.337\n",
      "Iter: 92000\n",
      "D loss: 0.5951\n",
      "G_loss: 2.813\n",
      "Iter: 93000\n",
      "D loss: 0.4925\n",
      "G_loss: 2.776\n",
      "Iter: 94000\n",
      "D loss: 0.6166\n",
      "G_loss: 2.337\n",
      "Iter: 95000\n",
      "D loss: 0.4698\n",
      "G_loss: 2.462\n",
      "Iter: 96000\n",
      "D loss: 0.4954\n",
      "G_loss: 2.594\n",
      "Iter: 97000\n",
      "D loss: 0.5247\n",
      "G_loss: 2.657\n",
      "Iter: 98000\n",
      "D loss: 0.5329\n",
      "G_loss: 2.609\n",
      "Iter: 99000\n",
      "D loss: 0.4819\n",
      "G_loss: 2.541\n",
      "Iter: 100000\n",
      "D loss: 0.5111\n",
      "G_loss: 2.547\n",
      "Iter: 101000\n",
      "D loss: 0.5492\n",
      "G_loss: 3.192\n",
      "Iter: 102000\n",
      "D loss: 0.6362\n",
      "G_loss: 2.235\n",
      "Iter: 103000\n",
      "D loss: 0.5294\n",
      "G_loss: 2.51\n",
      "Iter: 104000\n",
      "D loss: 0.6132\n",
      "G_loss: 2.537\n",
      "Iter: 105000\n",
      "D loss: 0.4506\n",
      "G_loss: 2.535\n",
      "Iter: 106000\n",
      "D loss: 0.5382\n",
      "G_loss: 2.484\n",
      "Iter: 107000\n",
      "D loss: 0.5204\n",
      "G_loss: 2.557\n",
      "Iter: 108000\n",
      "D loss: 0.4841\n",
      "G_loss: 2.519\n",
      "Iter: 109000\n",
      "D loss: 0.4667\n",
      "G_loss: 3.113\n",
      "Iter: 110000\n",
      "D loss: 0.483\n",
      "G_loss: 2.436\n",
      "Iter: 111000\n",
      "D loss: 0.5466\n",
      "G_loss: 2.396\n",
      "Iter: 112000\n",
      "D loss: 0.4642\n",
      "G_loss: 2.672\n",
      "Iter: 113000\n",
      "D loss: 0.5338\n",
      "G_loss: 2.659\n",
      "Iter: 114000\n",
      "D loss: 0.4833\n",
      "G_loss: 3.16\n",
      "Iter: 115000\n",
      "D loss: 0.5349\n",
      "G_loss: 2.33\n",
      "Iter: 116000\n",
      "D loss: 0.5158\n",
      "G_loss: 2.623\n",
      "Iter: 117000\n",
      "D loss: 0.5248\n",
      "G_loss: 2.392\n",
      "Iter: 118000\n",
      "D loss: 0.4819\n",
      "G_loss: 3.047\n",
      "Iter: 119000\n",
      "D loss: 0.6127\n",
      "G_loss: 2.669\n",
      "Iter: 120000\n",
      "D loss: 0.4744\n",
      "G_loss: 2.655\n",
      "Iter: 121000\n",
      "D loss: 0.478\n",
      "G_loss: 2.87\n",
      "Iter: 122000\n",
      "D loss: 0.4938\n",
      "G_loss: 2.279\n",
      "Iter: 123000\n",
      "D loss: 0.3975\n",
      "G_loss: 2.303\n",
      "Iter: 124000\n",
      "D loss: 0.4742\n",
      "G_loss: 2.565\n",
      "Iter: 125000\n",
      "D loss: 0.5618\n",
      "G_loss: 2.866\n",
      "Iter: 126000\n",
      "D loss: 0.4633\n",
      "G_loss: 3.169\n",
      "Iter: 127000\n",
      "D loss: 0.6386\n",
      "G_loss: 2.984\n",
      "Iter: 128000\n",
      "D loss: 0.514\n",
      "G_loss: 2.731\n",
      "Iter: 129000\n",
      "D loss: 0.4245\n",
      "G_loss: 2.985\n",
      "Iter: 130000\n",
      "D loss: 0.4184\n",
      "G_loss: 2.614\n",
      "Iter: 131000\n",
      "D loss: 0.553\n",
      "G_loss: 2.525\n",
      "Iter: 132000\n",
      "D loss: 0.5026\n",
      "G_loss: 3.089\n",
      "Iter: 133000\n",
      "D loss: 0.5902\n",
      "G_loss: 2.746\n",
      "Iter: 134000\n",
      "D loss: 0.5378\n",
      "G_loss: 2.818\n",
      "Iter: 135000\n",
      "D loss: 0.5375\n",
      "G_loss: 2.596\n",
      "Iter: 136000\n",
      "D loss: 0.6198\n",
      "G_loss: 2.525\n",
      "Iter: 137000\n",
      "D loss: 0.4122\n",
      "G_loss: 2.355\n",
      "Iter: 138000\n",
      "D loss: 0.388\n",
      "G_loss: 2.749\n",
      "Iter: 139000\n",
      "D loss: 0.4281\n",
      "G_loss: 3.191\n",
      "Iter: 140000\n",
      "D loss: 0.4726\n",
      "G_loss: 2.929\n",
      "Iter: 141000\n",
      "D loss: 0.3752\n",
      "G_loss: 2.99\n",
      "Iter: 142000\n",
      "D loss: 0.4501\n",
      "G_loss: 2.691\n",
      "Iter: 143000\n",
      "D loss: 0.4338\n",
      "G_loss: 2.745\n",
      "Iter: 144000\n",
      "D loss: 0.4913\n",
      "G_loss: 2.605\n",
      "Iter: 145000\n",
      "D loss: 0.4668\n",
      "G_loss: 2.998\n",
      "Iter: 146000\n",
      "D loss: 0.4267\n",
      "G_loss: 3.193\n",
      "Iter: 147000\n",
      "D loss: 0.5045\n",
      "G_loss: 2.934\n",
      "Iter: 148000\n",
      "D loss: 0.4293\n",
      "G_loss: 2.886\n",
      "Iter: 149000\n",
      "D loss: 0.41\n",
      "G_loss: 2.821\n",
      "Iter: 150000\n",
      "D loss: 0.456\n",
      "G_loss: 3.142\n",
      "Iter: 151000\n",
      "D loss: 0.5214\n",
      "G_loss: 3.365\n",
      "Iter: 152000\n",
      "D loss: 0.4952\n",
      "G_loss: 2.822\n",
      "Iter: 153000\n",
      "D loss: 0.3576\n",
      "G_loss: 3.181\n",
      "Iter: 154000\n",
      "D loss: 0.4782\n",
      "G_loss: 2.814\n",
      "Iter: 155000\n",
      "D loss: 0.3323\n",
      "G_loss: 2.952\n",
      "Iter: 156000\n",
      "D loss: 0.4167\n",
      "G_loss: 2.887\n",
      "Iter: 157000\n",
      "D loss: 0.4067\n",
      "G_loss: 2.802\n",
      "Iter: 158000\n",
      "D loss: 0.4317\n",
      "G_loss: 3.435\n",
      "Iter: 159000\n",
      "D loss: 0.5026\n",
      "G_loss: 2.894\n",
      "Iter: 160000\n",
      "D loss: 0.484\n",
      "G_loss: 3.14\n",
      "Iter: 161000\n",
      "D loss: 0.4888\n",
      "G_loss: 2.93\n",
      "Iter: 162000\n",
      "D loss: 0.4307\n",
      "G_loss: 3.082\n",
      "Iter: 163000\n",
      "D loss: 0.4265\n",
      "G_loss: 2.895\n",
      "Iter: 164000\n",
      "D loss: 0.3858\n",
      "G_loss: 2.737\n",
      "Iter: 165000\n",
      "D loss: 0.4898\n",
      "G_loss: 2.848\n",
      "Iter: 166000\n",
      "D loss: 0.3699\n",
      "G_loss: 2.885\n",
      "Iter: 167000\n",
      "D loss: 0.365\n",
      "G_loss: 2.97\n",
      "Iter: 168000\n",
      "D loss: 0.4705\n",
      "G_loss: 3.169\n",
      "Iter: 169000\n",
      "D loss: 0.3337\n",
      "G_loss: 2.9\n",
      "Iter: 170000\n",
      "D loss: 0.4513\n",
      "G_loss: 2.832\n",
      "Iter: 171000\n",
      "D loss: 0.4868\n",
      "G_loss: 2.661\n",
      "Iter: 172000\n",
      "D loss: 0.3042\n",
      "G_loss: 2.955\n",
      "Iter: 173000\n",
      "D loss: 0.4391\n",
      "G_loss: 2.898\n",
      "Iter: 174000\n",
      "D loss: 0.4005\n",
      "G_loss: 3.188\n",
      "Iter: 175000\n",
      "D loss: 0.348\n",
      "G_loss: 3.195\n",
      "Iter: 176000\n",
      "D loss: 0.3968\n",
      "G_loss: 3.074\n",
      "Iter: 177000\n",
      "D loss: 0.3627\n",
      "G_loss: 3.012\n",
      "Iter: 178000\n",
      "D loss: 0.4684\n",
      "G_loss: 2.997\n",
      "Iter: 179000\n",
      "D loss: 0.3551\n",
      "G_loss: 3.415\n",
      "Iter: 180000\n",
      "D loss: 0.497\n",
      "G_loss: 3.111\n",
      "Iter: 181000\n",
      "D loss: 0.4638\n",
      "G_loss: 2.739\n",
      "Iter: 182000\n",
      "D loss: 0.4347\n",
      "G_loss: 3.032\n",
      "Iter: 183000\n",
      "D loss: 0.4064\n",
      "G_loss: 2.828\n",
      "Iter: 184000\n",
      "D loss: 0.3079\n",
      "G_loss: 3.234\n",
      "Iter: 185000\n",
      "D loss: 0.4415\n",
      "G_loss: 2.797\n",
      "Iter: 186000\n",
      "D loss: 0.4457\n",
      "G_loss: 3.23\n",
      "Iter: 187000\n",
      "D loss: 0.3584\n",
      "G_loss: 3.375\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "for it in range(1000000):\n",
    "    if it % 1000 == 0:\n",
    "        samples = sess.run(G_sample, feed_dict={Z: sample_Z(16, Z_dim)})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    "\n",
    "    X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "\n",
    "    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(mb_size, Z_dim)})\n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(mb_size, Z_dim)})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'. format(D_loss_curr))\n",
    "        print('G_loss: {:.4}'.format(G_loss_curr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
